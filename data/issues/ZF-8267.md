---
layout: issue
title: "Significant memory leak in Zend_Search_Lucene_Search_QueryHit"
id: ZF-8267
---

ZF-8267: Significant memory leak in Zend\_Search\_Lucene\_Search\_QueryHit
--------------------------------------------------------------------------

 Issue Type: Bug Created: 2009-11-09T20:07:23.000+0000 Last Updated: 2009-12-11T07:30:01.000+0000 Status: Resolved Fix version(s): 
 Reporter:  Chris Pliakas (cpliakas)  Assignee:  Alexander Veremyev (alexander)  Tags: - Zend\_Search\_Lucene
 
 Related issues: 
 Attachments: 
### Description

Searching an index with around 600 documents was consuming around 18M of memory. After further investigation, I narrowed the problem down to the retrieval of field data via the Zend\_Search\_Lucene\_Search\_QueryHit object. The following code examples illustrate the bug:

 
    <pre class="highlight"> 
    <?php
    // Normal page usage: 24285096
    
    $hits = $index->find($query);
    foreach ($hits as $hit) {
      $value = $hit->nid;
    }
    echo memory_get_usage(); // 42294776
    
    ?>


 
    <pre class="highlight"> 
    <?php
    // Executing same query with different retrieval method
    
    $hits = $index->find($query);
    foreach ($hits as $hit) {
      $value = $index->getDocument($hit->id)->getFieldValue('nid');
    }
    echo memory_get_usage(); // 25824168
    
    ?>


The issue was originally reported in the Search Lucene API module for Drupal at <http://drupal.org/node/628254>. Although the easy workaround is to use method #2, method #1 is more terse and would be the preferable retrieval method.

Thanks for a great component, Chris

 

 

### Comments

Posted by Alexander Veremyev (alexander) on 2009-12-11T06:51:58.000+0000

That's not a memory leak. It's correct behavior.

Each query hit object stores loaded document data. And it uses lazy loading.

So your second example doesn't load document data within query hit processing. You do it manually. But! manually loaded document goes out of scape at each "foreach" iteration.

Try this code:

 
    <pre class="highlight">
    $hits = $index->find($query);
    foreach ($hits as $hit) {
      $value = $hit->nid;
    }
    printf("%d\n", memory_get_usage()); // 42294776
    
    unset($hits);
    
    printf("%d\n", memory_get_usage());


unset($hits) destroys query hits objects and returns used memory.

On the other hand, you are right. It's not necessary to have documents stored in memory for some situations.

 

 

Posted by Chris Pliakas (cpliakas) on 2009-12-11T07:30:01.000+0000

Hey Alexander.

Thanks for the detailed explanation, and I see why this is happening. In terms of my implementation on Drupal.org, the $hit->nid works great for the paged results, but there is a cool faceted search feature that scans the results and calculates the number of each facet in the result set. Surprisingly this is very quick even with thousands of documents, but I was reaching the memory limit when using the $hit->nid method. $index->getDocument($hit->id)->getFieldValue('nid') has a much smaller footprint and avoided the memory spike making the module much more scalable, and I don't really need to store the document in memory after it is iterated over anyways. Drupal sites tends to take up a significant amount of memory, so the less I can use the better.

Thanks for a great component. People on Drupal.org are finding it very useful. ~Chris

 

 