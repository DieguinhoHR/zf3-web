---
layout: issue
title: "regex for wildcard query (single-placeholder) is wrong"
id: ZF-2598
---

ZF-2598: regex for wildcard query (single-placeholder) is wrong
---------------------------------------------------------------

 Issue Type: Docs: Improvement Created: 2008-02-07T09:15:33.000+0000 Last Updated: 2012-05-17T18:56:27.000+0000 Status: In Progress Fix version(s): 
 Reporter:  Stefan Oestreicher (dlx)  Assignee:  Alexander Veremyev (alexander)  Tags: - Zend\_Search\_Lucene
- FixForZF1.12
- zf-crteam-padraic
- zf-crteam-priority
 
 Related issues: 
 Attachments: 
### Description

If I search for "lebe?" it correctly matches "leber", "leben" etc. But if I search for "le?en" it doesn't match anything. I dumped the used pattern and it seems there is a bug. The pattern generated for "lebe?" is "/^lebe.$/u" which is correct but for "le?en" the generated pattern is "/^.$/u" which is obviously plain wrong. I didn't track it further but my guess would be that the problem is in the QueryParser. It seems to work only if the placeholder is at the start or end of the term but fails if it's in between.

 

 

### Comments

Posted by Stefan Oestreicher (dlx) on 2008-02-07T09:43:49.000+0000

I found the problem. This happends because the wildcard-term is tokenized but my tokenizer discards tokens smaller than 2 characters. Therefore "le" before the questionmark and "en" after it are discarded and only the questionmark remains. But since it's only tokenized to ensure that it's not a phrase I'd say it's an error that the tokens are looped through.

instead of $tokens = Zend\_Search\_Lucene\_Analysis\_Analyzer::getDefault()->tokenize($subPatternL2, $encoding); if (count($tokens) > 1) { throw new Zend\_Search\_Lucene\_Search\_QueryParserException('Wildcard search is supported only for non-multiple word terms'); } #var\_dump($tokens); foreach ($tokens as $token) { $pattern .= $token->getTermText(); }

do this $tokens = Zend\_Search\_Lucene\_Analysis\_Analyzer::getDefault()->tokenize($subPatternL2, $encoding); if (count($tokens) > 1) { throw new Zend\_Search\_Lucene\_Search\_QueryParserException('Wildcard search is supported only for non-multiple word terms'); } $pattern .= $subPatternL2;

and it should work as expected

 

 

Posted by Stefan Oestreicher (dlx) on 2008-02-11T08:55:09.000+0000

i completely forgot to mention, the postet code is in Zend\_Search\_Lucene\_Search\_QueryEntry\_Term around the line 145

btw, my fix won't work correctly in all cases since any special characters at the start and end of the term won't be discarded as they would be if the tokenized term would be used (punctuation, etc.). I think a better solution would be to allow for disabling the analyzer filters:

$analyzer = Zend\_Search\_Lucene\_Analysis\_Analyzer::getDefault(); $analyzer->setFiltersEnabled(false); $tokens = $analyzer->tokenize($subPatternL2, $encoding); $analyzer->setFiltersEnabled(true); if (count($tokens) > 1) { throw new Zend\_Search\_Lucene\_Search\_QueryParserException('Wildcard search is supported only for non-multiple word terms'); } foreach ($tokens as $token) { $pattern .= $token->getTermText(); }

i think this sould work perfectly with the default anaylzers, although it may still be a problem with custom written analyzers?

 

 

Posted by Alexander Veremyev (alexander) on 2008-02-20T17:59:13.000+0000

Stefan,

Thank you very much for your detailed research of the problem!

It has one additional aspect. Filter are used also for normalizing terms (e.g. converting to lowercase, stemming and so on). Such normalization has to be performed during indexing and query parsing to get correct terms matching.

So we have two types of filters: 1) normalization filters 2) "filtering" filters (e.g. stop words , short words filters). That needs more accurate API.

I've decreased issue priority to postpone it to post-1.5 release period.

PS Actually normalization filters may transform term completely (e.g. stemming filters). I am not sure, such filters may be compatible with wildcard searching.

 

 

Posted by Wil Sinclair (wil) on 2008-04-18T13:11:50.000+0000

This doesn't appear to have been fixed in 1.5.0. Please update if this is not correct.

 

 

Posted by Corvus Corax (corvuscorax) on 2009-09-02T08:17:32.000+0000

As far as I can see, it still is an issue. But it might not need to be fixed

A possible workaround solution is for the user to use a different analyzer for searching and for indexing.

One example where I did this is the use of synonyme analysers, that provide several alternative tokens for a single word in the original text. If all those alternatives end up in the index, its enough to search for a single one of them, since all alternatives are already in the index. (And unless ZF-7738 gets integrated, multiple tokens for a single term raise exceptions in fuzzy and wildcard searches anyway)

Similar with stop word filtering. It makes sense during indexing, but its counter-productive during search.

A stem word filter however may make sense to be applied both during indexing and during search. (though it may affect wildcard searches weirdly)

Since its no problem to switch analyzers between the different tasks I don't think this bug needs to be fixed. It my make more sense to document these effects in the official documentation.

 

 

Posted by PÃ¡draic Brady (padraic) on 2011-08-14T18:41:01.000+0000

Rather than fix this, which seems a bit convoluted, the approach suggested in last comment is sound. Therefore have re-categorised this to a Critical Docs Improvement.

 

 

Posted by Adam Lundrigan (adamlundrigan) on 2012-05-17T18:56:27.000+0000

Would anyone like to write such a documentation improvement before 1.12 is frozen?

 

 