---
layout: issue
title: "Strange tokenizing from analyzer"
id: ZF-7688
---

ZF-7688: Strange tokenizing from analyzer
-----------------------------------------

 Issue Type: Bug Created: 2009-08-25T23:29:01.000+0000 Last Updated: 2011-08-09T15:29:05.000+0000 Status: Open Fix version(s): 
 Reporter:  Erik Wijdemans (mindexpander)  Assignee:  Alexander Veremyev (alexander)  Tags: - Zend\_Search\_Lucene
 
 Related issues: - [ZF-7685](/issues/browse/ZF-7685)
- [ZF-7738](/issues/browse/ZF-7738)
 
 Attachments: - [multi-token-plus-dummy-indexer-highlighting.patch](/issues/secure/attachment/12174/multi-token-plus-dummy-indexer-highlighting.patch)
- [preprocessor\_multi\_token\_awareness.patch](/issues/secure/attachment/12169/preprocessor_multi_token_awareness.patch)
- [preprocessor\_multi\_token\_awareness\_and\_highlighting.patch](/issues/secure/attachment/12173/preprocessor_multi_token_awareness_and_highlighting.patch)
- [Term.php.patch](/issues/secure/attachment/12166/Term.php.patch)
 
### Description

I have an index with a Zend\_Search\_Lucene\_Analysis\_Analyzer\_Common\_Utf8Num\_CaseInsensitive analyzer.

When I query the index with the query "foo\_bar\*" (without quotes) I get the following exception: Zend\_Search\_Lucene\_Search\_QueryParserException' with message 'Wildcard search is supported only for non-multiple word terms' in Zend/Search/Lucene/Search/Query/Preprocessing/Term.php:182

I get no exception when I query with the query "foo bar\*".

I've looked within Term.php and in the first example with "foo\_bar\*" as query, the analyzer tokenizes the query into 'foo' and 'bar' but in the second example to only 'bar'. The first example given me therefor an exception because on line 180: if (count($tokens) > 1) { throw exception; }

I'm a bit confused on how the analyzer works because if the analyzer tokenizes words in cases of characters like an underscore or an '@'-sign _and_ with plain spaces I would expect to get an exception in both cases. For some reason, it doesn't seem to tokenize the query "foo bar\*" into 2 tokens where I would've expected it.

Now, to work around this I could rerun the analyzer to check if the query got tokenized into multiple tokens. If the only 1 token is found i could append a wildcard (because my app requires it that way) and otherwise I should not append it.

Is this just a limitation of the module or doesn't the analyzer work properly? Please shine some light into this one :) Thanks!

 

 

### Comments

Posted by Corvus Corax (corvuscorax) on 2009-08-27T09:11:13.000+0000

I was able to reproduce this.

query parser turns "foo\_bar_" (with quotes) into Zend\_Search\_Lucene\_Search\_Query\_Boolean Object ( [\_subqueries:private] => Array ( [0] => Zend\_Search\_Lucene\_Search\_Query\_Preprocessing\_Phrase Object ( [\_phrase:private] => foo\_bar_ [\_phraseEncoding:private] => utf-8 [\_field:private] => [\_slop:private] => [\_matches:protected] => [\_boost:private] => 1 [\_weight:protected] => [\_currentColorIndex:private] => 0 )

 
        )
    
    [_signs:private] => Array
        (
            [0] => 
        )
    
    [_resVector:private] => 
    [_coord:private] => 
    [_boost:private] => 1
    [_weight:protected] => 
    [_currentColorIndex:private] => 0


) which is ok. same with "foo bar\*"

foo bar\* turns into Zend\_Search\_Lucene\_Search\_Query\_Boolean Object ( [\_subqueries:private] => Array ( [0] => Zend\_Search\_Lucene\_Search\_Query\_Preprocessing\_Term Object ( [\_word:private] => foo [\_encoding:private] => utf-8 [\_field:private] => [\_matches:protected] => [\_boost:private] => 1 [\_weight:protected] => [\_currentColorIndex:private] => 0 )

 
            [1] => Zend_Search_Lucene_Search_Query_Preprocessing_Term Object
                (
                    [_word:private] => bar*
                    [_encoding:private] => utf-8
                    [_field:private] => 
                    [_matches:protected] => 
                    [_boost:private] => 1
                    [_weight:protected] => 
                    [_currentColorIndex:private] => 0
                )
    
        )
    
    [_signs:private] => Array
        (
            [0] => 
            [1] => 
        )
    
    [_resVector:private] => 
    [_coord:private] => 
    [_boost:private] => 1
    [_weight:protected] => 
    [_currentColorIndex:private] => 0


) which is ok too (of which both "foo" and "bar\*" do not cause issues because each of them have a count($tokens) of 1 within Term.php line 182

"foo\_bar_" however leads to end\_Search\_Lucene\_Search\_Query\_Boolean Object ( [\_subqueries:private] => Array ( [0] => Zend\_Search\_Lucene\_Search\_Query\_Preprocessing\_Term Object ( [\_word:private] => foo\_bar_ [\_encoding:private] => utf-8 [\_field:private] => [\_matches:protected] => [\_boost:private] => 1 [\_weight:protected] => [\_currentColorIndex:private] => 0 )

 
        )
    
    [_signs:private] => Array
        (
            [0] => 
        )
    
    [_resVector:private] => 
    [_coord:private] => 
    [_boost:private] => 1
    [_weight:protected] => 
    [_currentColorIndex:private] => 0


) that leads to "foo\_bar" being passed as argument 0 ($subPatterns[0]) in class Zend\_Search\_Lucene\_Search\_Query\_Preprocessing\_Term line 180: $tokens = Zend\_Search\_Lucene\_Analysis\_Analyzer::getDefault()->tokenize($subPattern[0], $subPatternsEncoding); which leads to the following array: ( [0] => Zend\_Search\_Lucene\_Analysis\_Token Object ( [\_termText:private] => foo [\_startOffset:private] => 0 [\_endOffset:private] => 3 [\_positionIncrement:private] => 1 )

 
    [1] => Zend_Search_Lucene_Analysis_Token Object
        (
            [_termText:private] => bar
            [_startOffset:private] => 4
            [_endOffset:private] => 7
            [_positionIncrement:private] => 1
        )


) which has a count() of 2 and raises the above error!

so basically it comes down to

foo bar\* is interpreted as foo OR bar\*

while foo\_bar\* (doe to the space interpretation of \_ in the analyzer but NOT by the query analyzer) is interpreted as something weird like (semantic wise) (foo OR bar)\* which doesn't work.

I run into the exact same symtom when building an analyzer that returned more than one result token for the same source token (synonyme analyzer) and accidentally using that on a query string.

Work around: make sure no tokens in a query string contain characters that get interpreted as by the analyzer OR set the default analyzer to a self written one that treats underscore and similar characters as non spaces

fix: don't know, maybe change AnalyzerCommon's default behaviour regarding underscores ?

I really hope this wiki software keeps my formatting or this will be really hard to read ;)

 

 

Posted by Corvus Corax (corvuscorax) on 2009-08-27T09:39:11.000+0000

Hmm formatting is still semi ok.

I wonder, why does Term.php do a tokenisation of the pattern in line 180, just to add all the tokens back together into one string in line 186, and in between complain if its more than one?

I guess throwing the original error is valid because a search for foo\_bar\* would never succeed, since the index (due to \_ being interpreted as space by the tokenizer) only stored "foo" and "barblub" even if the indexed text had "foo\_barblub" in it

so what the user really wanted "foo\_bar_" to be turned to is not a query wildcard to "foo\_bar_" but a Zend\_Search\_Lucene\_Search\_Query\_Phrase ( array("foo","bar_") ) with bar_ interpreted as a wildcard query.

HOWEVER this is only true if (count($tokens) >1) because of "foo\_bar" gets tokenized as two separate words due to a char interpreted as space.

assuming you had a synonyme analyzer that had "bar" listed as synonyme for "foo"

then "foo_" would rise the same error in Term.php line 182 due to count=2 however what the user wanted there is either foo_ OR bar\* or foo\* without searching for bar

how to solve that? - I'd suggest to not use multi-token analyzers on query strings. Its unnecceasary if both variants are already stored in the index anyway. foo\_bar\* could then be safely turned into a phrase search (if phrase searches containing wildcard queries is valid in itself, didn't test that ;)

(I am currently working on a patch to submit that allows TokenFilters that create multiple tokens out of one, like Java Lucene does. I have the code working here, but I'm waiting for my CLA being approved ;)

 

 

Posted by Corvus Corax (corvuscorax) on 2009-08-28T02:38:12.000+0000

The equivalent error occurs when doing a fuzzy search for something like

mod\_php~

Fatal error: Uncaught exception 'Zend\_Search\_Lucene\_Search\_QueryParserException' with message 'Fuzzy search is supported only for non-multiple word terms' in /home/raven/studium/zendtest/Zend/Search/Lucene/Search/Query/Preprocessing/Fuzzy.php:217 Stack trace:

0 Zend/Search/Lucene/Search/Query/Preprocessing/Fuzzy.php(130): Zend\_Search\_Lucene\_Search\_Query\_Preprocessing\_Fuzzy->rewrite(Object(Zend\_Search\_Lucene))
================================================================================================================================================================

1 Zend/Search/Lucene/Search/Query/Boolean.php(146): Zend\_Search\_Lucene\_Search\_Query\_Preprocessing\_Fuzzy->rewrite(Object(Zend\_Search\_Lucene))
====================================================================================================================================================

2 Zend/Search/Lucene.php(905): Zend\_Search\_Lucene\_Search\_Query\_Boolean->rewrite(Object(Zend\_Search\_Lucene))
==================================================================================================================

3 [internal function]: Zend\_Search\_Lucene->find(Object(Zend\_Search\_Lucene\_Search\_Query\_Boolean))
=======================================================================================================

4 Zend/Search/Lucene/Proxy.php(346): call\_user\_func\_array(Array, Array)
==========================================================================

5 index.php(355): Zend\_Search\_Lucene\_Proxy->find in /Zend/Search/Lucene/Search/Query/Preprocessing/Fuzzy.php on line 217
===========================================================================================================================

 

 

Posted by Corvus Corax (corvuscorax) on 2009-08-28T04:42:21.000+0000

This patch fixes this issue for foo\_bar\* by returning a phrase query that has foo in position 0 and all possible matching terms for a bar\* wildcard query in posion 1

Known bugs:

A search for foo_\_bar_ will not raise the original error ( since the partial string "\_bar" creates only one token with text "bar") therefore it will be turned into a wildcard query for foo\*bar\* as with the old code.

foo_bar_ will not find foo\_bar in the index since only foo and bar have been indexed.

It may be necessary to change the indicator when to split the pattern up into several. count($analyzer->tokenize()) seems to be a bad indicator since it will give 1 for a string like "\_foo". Possible but hacky solution: test wether tokenize("x".$x) leads to array("x".$y) or array("x",$y) (comma versus dot) Mr Veremyev, what do you think?

 

 

Posted by Corvus Corax (corvuscorax) on 2009-08-28T09:00:55.000+0000

I added another patch. (preprocessor\_multi\_token\_awareness.patch)

It adds complete multi token awareness to both the Fuzzy and the Term preprocessor, taking $token->getPositionIncrement() into account to create exact phrase queries in case a substring within a fuzzy or wildcard term gets tokenized into multiple tokens.

I tested it briefly before posting on both the original foo\_bar\* problems as well as "real" alternative token scenarios (tokenizer returning two alternative tokens for the same string) and combinations of those.

Unfortunately I did not come up with a more sensible test wether the first character in a "subPattern" is treated as a word boundary by the used analyzer, so I used the previously described hack :(

Do you know a better way?

Maybe trying to tokenize the first character only and see if there is a non empty result? (but then one has to worry about encoding and multibytenesses too)

 

 

Posted by Corvus Corax (corvuscorax) on 2009-08-30T14:56:45.000+0000

Another patch.

I fixed the test for wether the first character of a subPattern is tokenisable or not in a IMHO reasonable way.

There is a problem with the fixed pattern search however, which is, the existing highlighting code won't work.

I need to take this as an opportunity to say that I heartly disagree with the way highlighting is done currently, because it duplicates functionality both in code and exection.

In a bad way.

And A lot!

With the cascaded protected \_highlightMatches() function within queries, simple queries (for example Query\_Term) just highlight EXACT matches, thus needing the $document->highlight function to tokenize the entire document.

For every single query term.

Worse, with complicated tokens like Fuzzy or Wildcard, the Query's highlight function itself has to tokenize the document AGAIN to find matches - for every single Fuzzy/Wildcard term - which then are given back to the highlighter class to tokenize the document AGAIN to finally highlight them.

Everywhere and all the \_highlightMatches() function also duplicates the functionality of rewrite(), doing more or less the same things and stumbling over the same pitfalls (mostly in combination with strings that create multiple tokens)

In practice (as in production setup) I had cases where the search took 3 seconds, and the highlighting of 10 relatively short result excerpts kept the servers CPU busy for 40!!! seconds. That is completely and utterly unusable for a production web application (I have to say though, there were quite many terms in that index due to a synonym plus stem analyzer being used (around 100k terms)

It would be easier (and faster) to just INDEX the to be highlighted document into a temporary In-Memory Lucene Index, and then rewrite the query and feed $query->getQueryTerms() to the $highlighter.

But in practice even that would be overkill. In 99.99% of the cases the to be highlighted text is text stored somewhere in the index ANYWAY, since the to be highlighted text is part of a document originally indexed, AKA a search result. So calling $query->rewrite() with the search index would provide all the required data to highlight the result.

I used this approach in this patch. Pro: It fixes highlighting: Everything the query finds is also highlighted succesfully Contra: It changes the API: Calling highlightMatches() on a non-rewritten query will rise an exception.

Better probably would be to do the temporary indexing solution mentioned above.

In practice (as in my production setup) I went one step further. We didn't even use the DocumentHTML class for highlighting, the highlighting code instead called:

$analyzer->tokenize() on the to be highlighted document ONCE and stored the result in an array.

Then I called $query()->rewrite()->getQueryTokens() and stored that in a second array.

PHP's array\_intersect() gives me all the tokens matched in the to be highlighted text. Including their string positions. All thats needed is to use mb\_substr() (its multi-byte safe - unlike the original DocumentHTML highlight code!) on the original texts to get the raw, non tokenized versions of the to be highligted words.

a simple preg\_replace later and the text is highlighted. No DOM class involved. (But thats up to the user of course)

Speedup between Lucene's Highlighter and mine with the same 10 documents and the same index: 40 seconds went down to 0.8, thats factor 50!

All in all this tells me, Zend Lucene needs some serieous internal redesign as far as highlighting goes. BADLY.

So I don't really care wether my fix currently breaks the original highlighting code ;)

 

 

Posted by Corvus Corax (corvuscorax) on 2009-08-30T18:36:30.000+0000

Ok. Highlighting - new style :)

This patch gets rid of all protected \_highlightMatches() functions in all Queries

Query->highlightmatches and htmlFragmentHighlightMatches() now create a new "dummy" index (class Zend\_Search\_Lucene\_TempIndex) which has the ability to temporarily store a single document (or a few documents) which is promptly added via addDocument() from the provided HTML code (which correctly tokenizes said document using the default-analyzer and stores found terms in an array)

then $query->rewrite(...) is called with this index, to rewrite the query based on the dummy index containing only the terms found in the to be highlighted text.

which then are forwarded to the highlighter itself.

I didn't test it with range queries though, but from how Range->rewrite() looks, all needed functions are supported, too.

Henceforth multi-terms should no longer be a problem >:)

Code might need cleanup and some alterations to be conformous with Zend and Lucene coding rules and policies, though I tried to keep it tidy ;)

 

 

Posted by Corvus Corax (corvuscorax) on 2009-08-31T10:18:41.000+0000

I put the patches fixing this bug into seperate issues ( ZF-7738, ZF-7736 ) , since they somehow outgrew the context of this particular issue.

 

 

Posted by Sylvestre Ledru (sylvestre) on 2011-08-09T15:29:05.000+0000

Is there any chance that, one day, this bug could be fixed ? I have many users who are complaining about the underscore breaking the search ...

What kind of alternatives are available to Zend Lucene ?

Thanks

 

 